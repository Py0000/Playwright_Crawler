"""
def get_content_from_server_only(folder_path, actual_url, page):
    print("Getting content from server-side...")
    try:
        server_html_script = requests.get(actual_url).text
        soup = BeautifulSoup(server_html_script, "lxml")
        if soup is not None:
            crawler_support.save_html_script(folder_path, util_def.HTML_SCRIPT_BEF_FILE, soup.prettify())
        else:
            crawler_support.save_html_script(folder_path, util_def.HTML_SCRIPT_BEF_FILE, f"No server-side content for url: {actual_url}")

        crawler_support.get_all_html_tags(folder_path, soup, util_def.HTML_TAG_BEF_FILE)

        page.set_content(soup.prettify())
        wait_for_page_to_load(page, act_flag=False)
        get_screenshot(page, folder_path, util_def.SCREENSHOT_BEF_FILE)
        
    except Exception as e:
        crawler_support.save_html_script(folder_path, util_def.HTML_SCRIPT_FILE, f"Error occurred for url: {actual_url}\n{e}")
"""

def get_content_from_server_only(folder_path, device_conf, ref_flag, act_flag, ref_url, actual_url):
    print("Getting content from server-side...")
    try:
        p = sync_playwright().start()
        browser = p.chromium.launch(headless=False, slow_mo=50)
        device = ""
        is_desktop_device = util.desktop_configuration_checker(device_conf)
        if is_desktop_device:
            custom_user_agent = util_def.DESKTOP_USER_AGENT_MAP.get(device_conf)
            browser = p.chromium.launch(headless=True, slow_mo=50, args=custom_user_agent)
            context =  browser.new_context()
        else:
            if device_conf == util_def.MOBILE_USER:
                device = p.devices['Pixel 5']
            else:
                device = p.devices['Pixel 5'].copy()
                device['user_agent'] = util_def.MOBILE_BOT_AGENT
            context = browser.new_context(**device)
        
        page = context.new_page()

        if ref_flag:
            page.set_extra_http_headers({"Referer": ref_url})
            
        page.route('**/*', lambda route, request: 
               route.abort() if 'script' in request.resource_type else route.continue_())
        
        page.goto(actual_url)

        if act_flag:
            check_and_execute_user_actions(device_conf, act_flag, page)
        
        # Gets the html content 
        get_screenshot(page, folder_path, util_def.SCREENSHOT_BEF_FILE)
        server_content = page.content()
        soup = BeautifulSoup(server_content, "lxml")
        if soup is not None:
            crawler_support.save_html_script(folder_path, util_def.HTML_SCRIPT_BEF_FILE, soup.prettify())
        else:
            crawler_support.save_html_script(folder_path, util_def.HTML_SCRIPT_BEF_FILE, f"No server-side content for url: {actual_url}")

        crawler_support.get_all_html_tags(folder_path, soup, util_def.HTML_TAG_BEF_FILE)
    except Exception as e:
        crawler_support.save_html_script(folder_path, util_def.HTML_SCRIPT_BEF_FILE, f"Error occurred for url: {actual_url}\n{e}")